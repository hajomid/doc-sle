<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Disk Cache Modes | Virtualization Guide | SUSE Linux Enterprise Server 15</title><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /><link rel="stylesheet" type="text/css" href="static/css/style.css" /><link rel="stylesheet" type="text/css" href="static/css/highlight.css" /><meta name="generator" content="DAPS 2.4.0 using SUSE XSL Stylesheets 2.0.8 (based on DocBook XSL Stylesheets 1.78.1) - chunked" /><meta name="product-name" content="SUSE Linux Enterprise Server" /><meta name="product-number" content="15" /><meta name="book-title" content="Virtualization Guide" /><meta name="chapter-title" content="Chapter 15. Disk Cache Modes" /><meta name="tracker-url" content="https://bugzilla.suse.com/enter_bug.cgi" /><meta name="tracker-type" content="bsc" /><meta name="tracker-bsc-assignee" content="fs@suse.com" /><meta name="tracker-bsc-component" content="Documentation" /><meta name="tracker-bsc-product" content="Beta SUSE Linux Enterprise Server 15" /><link rel="home" href="index.html" title="SUSE Linux Enterprise Server Documentation" /><link rel="up" href="part.virt.common.html" title="Part III. Hypervisor-Independent Features" /><link rel="prev" href="part.virt.common.html" title="Part III. Hypervisor-Independent Features" /><link rel="next" href="sec.kvm.managing.clock.html" title="Chapter 16. VM Guest Clock Settings" /><script type="text/javascript">

var protocol = window.location.protocol.toLowerCase();
if ( protocol != 'file:' ) {
  var agent = navigator.userAgent.toLowerCase();
  var wanted = ( protocol == 'https:') ? 'https' : 'http';
  var file = 'fonts.css';
  document.write('<link rel="stylesheet" type="text/css" href="' + wanted + '://static.opensuse.org/fonts/'+ file +'"></link>');
}
else {
   document.write('<link rel="stylesheet" type="text/css" href="static/css/fonts-onlylocal.css"></link>');
}

</script><noscript><link rel="stylesheet" type="text/css" href="http://static.opensuse.org/fonts/fonts.css" /></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"></script><script src="static/js/script.js" type="text/javascript"></script><script src="static/js/highlight.min.js" type="text/javascript"></script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft offline js-off"><div id="_outer-wrap"><div id="_white-bg"><div id="_header"><div id="_logo"><img src="static/images/logo.png" alt="Logo" /></div><div class="crumbs"><a class="book-link" href="index.html" title="SUSE Linux Enterprise Server Documentation"><span class="book-icon">SUSE Linux Enterprise Server Documentation</span></a><span> › </span><a class="crumb" href="book.virt.html">Virtualization Guide</a><span> › </span><a class="crumb" href="part.virt.common.html">Hypervisor-Independent Features</a><span> › </span><a class="crumb" href="cha.cachemodes.html">Disk Cache Modes</a></div><div class="clearme"></div></div></div><div id="_toolbar-wrap"><div id="_toolbar"><div id="_toc-area" class="inactive"><a id="_toc-area-button" class="tool" title="Contents" accesskey="c" href="index.html"><span class="tool-spacer"><span class="toc-icon">Contents</span><span class="clearme"></span></span><span class="tool-label">Contents</span></a><div class="active-contents bubble-corner"></div><div class="active-contents bubble"><div class="bubble-container"><h6>Virtualization Guide</h6><div id="_bubble-toc"><ol><li class="inactive"><a href="cha.kvm.html"><span class="number"> </span><span class="name">About This Manual</span></a></li><li class="inactive"><a href="part.virt.intro.html"><span class="number">I </span><span class="name">Introduction</span></a><ol><li class="inactive"><a href="chap.virtualization.introduction.html"><span class="number">1 </span><span class="name">Virtualization Technology</span></a></li><li class="inactive"><a href="cha.xen.basics.html"><span class="number">2 </span><span class="name">Introduction to Xen Virtualization</span></a></li><li class="inactive"><a href="cha.kvm.intro.html"><span class="number">3 </span><span class="name">Introduction to KVM Virtualization</span></a></li><li class="inactive"><a href="cha.containers.intro.html"><span class="number">4 </span><span class="name">Introduction to Linux Containers</span></a></li><li class="inactive"><a href="cha.tools.intro.html"><span class="number">5 </span><span class="name">Virtualization Tools</span></a></li><li class="inactive"><a href="cha.vt.installation.html"><span class="number">6 </span><span class="name">Installation of Virtualization Components</span></a></li><li class="inactive"><a href="cha.virt.support.html"><span class="number">7 </span><span class="name">Supported Guests, Hosts and Features</span></a></li></ol></li><li class="inactive"><a href="part.virt.libvirt.html"><span class="number">II </span><span class="name">Managing Virtual Machines with <code class="systemitem">libvirt</code></span></a><ol><li class="inactive"><a href="cha.libvirt.overview.html"><span class="number">8 </span><span class="name">Starting and Stopping <code class="systemitem">libvirtd</code></span></a></li><li class="inactive"><a href="cha.kvm.inst.html"><span class="number">9 </span><span class="name">Guest Installation</span></a></li><li class="inactive"><a href="cha.libvirt.managing.html"><span class="number">10 </span><span class="name">Basic VM Guest Management</span></a></li><li class="inactive"><a href="cha.libvirt.connect.html"><span class="number">11 </span><span class="name">Connecting and Authorizing</span></a></li><li class="inactive"><a href="cha.libvirt.storage.html"><span class="number">12 </span><span class="name">Managing Storage</span></a></li><li class="inactive"><a href="cha.libvirt.networks.html"><span class="number">13 </span><span class="name">Managing Networks</span></a></li><li class="inactive"><a href="cha.libvirt.config.html"><span class="number">14 </span><span class="name">Configuring Virtual Machines</span></a></li></ol></li><li class="inactive"><a href="part.virt.common.html"><span class="number">III </span><span class="name">Hypervisor-Independent Features</span></a><ol><li class="inactive"><a href="cha.cachemodes.html"><span class="number">15 </span><span class="name">Disk Cache Modes</span></a></li><li class="inactive"><a href="sec.kvm.managing.clock.html"><span class="number">16 </span><span class="name">VM Guest Clock Settings</span></a></li><li class="inactive"><a href="chap.guestfs.html"><span class="number">17 </span><span class="name">libguestfs</span></a></li></ol></li><li class="inactive"><a href="part.virt.xen.html"><span class="number">IV </span><span class="name">Managing Virtual Machines with Xen</span></a><ol><li class="inactive"><a href="cha.xen.vhost.html"><span class="number">18 </span><span class="name">Setting Up a Virtual Machine Host</span></a></li><li class="inactive"><a href="cha.xen.network.html"><span class="number">19 </span><span class="name">Virtual Networking</span></a></li><li class="inactive"><a href="cha.xen.manage.html"><span class="number">20 </span><span class="name">Managing a Virtualization Environment</span></a></li><li class="inactive"><a href="cha.xen.vbd.html"><span class="number">21 </span><span class="name">Block Devices in Xen</span></a></li><li class="inactive"><a href="cha.xen.config.html"><span class="number">22 </span><span class="name">Virtualization: Configuration Options and Settings</span></a></li><li class="inactive"><a href="cha.xen.admin.html"><span class="number">23 </span><span class="name">Administrative Tasks</span></a></li><li class="inactive"><a href="cha.xen.xenstore.html"><span class="number">24 </span><span class="name">XenStore: Configuration Database Shared between Domains</span></a></li><li class="inactive"><a href="cha.xen.ha.html"><span class="number">25 </span><span class="name">Xen as a High-Availability Virtualization Host</span></a></li></ol></li><li class="inactive"><a href="part.virt.qemu.html"><span class="number">V </span><span class="name">Managing Virtual Machines with QEMU</span></a><ol><li class="inactive"><a href="cha.qemu.overview.html"><span class="number">26 </span><span class="name">QEMU Overview</span></a></li><li class="inactive"><a href="cha.qemu.host.html"><span class="number">27 </span><span class="name">Setting Up a KVM VM Host Server</span></a></li><li class="inactive"><a href="cha.qemu.guest_inst.html"><span class="number">28 </span><span class="name">Guest Installation</span></a></li><li class="inactive"><a href="cha.qemu.running.html"><span class="number">29 </span><span class="name">Running Virtual Machines with qemu-system-ARCH</span></a></li><li class="inactive"><a href="cha.qemu.monitor.html"><span class="number">30 </span><span class="name">Virtual Machine Administration Using QEMU Monitor</span></a></li></ol></li><li class="inactive"><a href="part.virt.lxc.html"><span class="number">VI </span><span class="name">Managing Virtual Machines with LXC</span></a><ol><li class="inactive"><a href="cha.lxc.html"><span class="number">31 </span><span class="name">Linux Containers</span></a></li><li class="inactive"><a href="cha.lxc2libvirt.html"><span class="number">32 </span><span class="name">Migration from LXC to <code class="systemitem">libvirt-lxc</code></span></a></li></ol></li><li class="inactive"><a href="gloss.vt.glossary.html"><span class="number"> </span><span class="name">Glossary</span></a></li><li class="inactive"><a href="app.vmdp.driver.html"><span class="number">A </span><span class="name">Virtual Machine Drivers</span></a></li><li class="inactive"><a href="app.kvm.html"><span class="number">B </span><span class="name">Appendix</span></a></li><li class="inactive"><a href="cha.xmtoxl.html"><span class="number">C </span><span class="name">XM, XL Toolstacks and Libvirt framework</span></a></li><li class="inactive"><a href="bk11apd.html"><span class="number">D </span><span class="name">GNU Licenses</span></a></li></ol></div><div class="clearme"></div></div></div></div><div id="_nav-area" class="inactive"><div class="tool"><span class="nav-inner"><span class="tool-label">Navigation</span><a accesskey="p" class="tool-spacer" title="Part III. Hypervisor-Independent Features" href="part.virt.common.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 16. VM Guest Clock Settings" href="sec.kvm.managing.clock.html"><span class="next-icon">→</span></a></span></div></div></div></div><div id="_fixed-header-wrap" class="inactive"><div id="_fixed-header"><div class="crumbs"><a class="book-link" href="index.html" title="SUSE Linux Enterprise Server Documentation"><span class="book-icon">SUSE Linux Enterprise Server Documentation</span></a><span> › </span><a class="crumb" href="book.virt.html">Virtualization Guide</a><span> › </span><a class="crumb" href="part.virt.common.html">Hypervisor-Independent Features</a><span> › </span><a class="crumb" href="cha.cachemodes.html">Disk Cache Modes</a></div><div class="buttons"><a class="top-button button" href="#">Top</a><div class="button"><a accesskey="p" class="tool-spacer" title="Part III. Hypervisor-Independent Features" href="part.virt.common.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 16. VM Guest Clock Settings" href="sec.kvm.managing.clock.html"><span class="next-icon">→</span></a></div><div class="clearme"></div></div><div class="clearme"></div></div></div><div id="_content" class="draft "><div class="documentation"><div class="chapter " id="cha.cachemodes"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname"><span class="productname"><span class="phrase">SUSE Linux Enterprise Server</span></span></span> <span class="productnumber"><span class="productnumber"><span class="phrase">15</span></span></span></div><div><h2 class="title"><span class="number">15 </span><span class="name">Disk Cache Modes</span> </h2><div class="doc-status"><ul><li><span class="ds-label">Filename: </span>vt_cachemodes.xml</li><li><span class="ds-label">ID: </span>cha.cachemodes</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="cha.cachemodes.html#sec.cachemodes"><span class="number">15.1 </span><span class="name">Disk Interface Cache Modes</span></a></span></dt><dt><span class="sect1"><a href="cha.cachemodes.html#cachemodes.descr"><span class="number">15.2 </span><span class="name">Description of Cache Modes</span></a></span></dt><dt><span class="sect1"><a href="cha.cachemodes.html#qemu.cachemodes.data_integrity"><span class="number">15.3 </span><span class="name">Data Integrity Implications of Cache Modes</span></a></span></dt><dt><span class="sect1"><a href="cha.cachemodes.html#qemu.cachemodes.performance"><span class="number">15.4 </span><span class="name">Performance Implications of Cache Modes</span></a></span></dt><dt><span class="sect1"><a href="cha.cachemodes.html#sec.cache.mode.live.migration"><span class="number">15.5 </span><span class="name">Effect of Cache Modes on Live Migration</span></a></span></dt></dl></div></div><div class="sect1 " id="sec.cachemodes"><div class="titlepage"><div><div><h2 class="title" id="sec.cachemodes"><span class="number">15.1 </span><span class="name">Disk Interface Cache Modes</span> <a title="Permalink" class="permalink" href="cha.cachemodes.html#sec.cachemodes">#</a></h2></div></div></div><p>
   Hypervisors allow for various storage caching
   strategies to be specified when configuring a VM Guest. Each guest disk
   interface can have one of the following cache modes specified:
   <span class="emphasis"><em>writethrough</em></span>, <span class="emphasis"><em>writeback</em></span>,
   <span class="emphasis"><em>none</em></span>, <span class="emphasis"><em>directsync</em></span>, or
   <span class="emphasis"><em>unsafe</em></span>. If no cache mode is specified,
   an appropriate default cache
   mode is used. These cache modes influence how host-based storage is accessed, as
   follows:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Read/write data may be cached in the host page cache.
    </p></li><li class="listitem "><p>
     The guest's storage controller is informed whether a write cache is
     present, allowing for the use of a flush command.
    </p></li><li class="listitem "><p>
     Synchronous write mode may be used, in which write requests are
     reported complete only when committed to the storage device.
    </p></li><li class="listitem "><p>
     Flush commands (generated by the guest storage controller) may be
     ignored for performance reasons.
    </p></li></ul></div><p>
   If a disorderly disconnection between the guest and its storage occurs, the
   cache mode in use will affect whether data loss occurs. The cache mode can
   also affect disk performance significantly. Additionally, some cache modes
   are incompatible with live migration, depending on several
   factors. There are no simple rules about what combination of cache mode,
   disk image format, image placement, or storage sub-system is best. The user
   should plan each guest's configuration carefully and experiment with
   various configurations to determine the optimal performance.
  </p></div><div class="sect1 " id="cachemodes.descr"><div class="titlepage"><div><div><h2 class="title" id="cachemodes.descr"><span class="number">15.2 </span><span class="name">Description of Cache Modes</span> <a title="Permalink" class="permalink" href="cha.cachemodes.html#cachemodes.descr">#</a></h2></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="idm139769515626144"><span class="term ">cache mode unspecified</span></dt><dd><p>
      In older QEMU versions, not specifying a cache mode meant that
      <span class="emphasis"><em>writethrough</em></span> would be used as the default. With
      modern versions—as shipped with <span class="productname"><span class="phrase">SUSE Linux Enterprise Server</span></span>—the various
      guest storage interfaces have been fixed to handle
      <span class="emphasis"><em>writeback</em></span> or <span class="emphasis"><em>writethrough</em></span>
      semantics more correctly. This allows for the default caching mode to be
      switched to <span class="emphasis"><em>writeback</em></span>. The guest driver for each of
      <code class="literal">ide</code>, <code class="literal">scsi</code>, and
      <code class="literal">virtio</code> have within their power to disable the write
      back cache, causing the caching mode used to revert to
      <span class="emphasis"><em>writethrough</em></span>. The typical guest's storage drivers
      will maintain the default caching mode as <span class="emphasis"><em>writeback</em></span>,
      however.
     </p></dd><dt id="cache.writethrough"><span class="term ">writethrough</span></dt><dd><p>
      This mode causes the hypervisor to interact with the disk image file or
      block device with <code class="literal">O_DSYNC</code> semantics. Writes are reported
      as completed only when the data has been committed
      to the storage device. The host page cache is used in what can be
      termed a writethrough caching mode. The guest's virtual storage
      adapter is informed that there is no writeback cache, so the guest
      would not need to send down flush commands to manage data integrity.
      The storage behaves as if there is a writethrough cache.
     </p></dd><dt id="cache.writeback"><span class="term ">writeback</span></dt><dd><p>
      This mode causes the hypervisor to interact with the disk image file or
      block device with neither <code class="literal">O_DSYNC</code> nor
      <code class="literal">O_DIRECT</code> semantics. The host page cache is used and
      writes are reported to the guest as completed when they are placed in the
      host page cache. The
      normal page cache management will handle commitment to the storage
      device. Additionally, the guest's virtual storage adapter is informed
      of the writeback cache, so the guest would be expected to send down
      flush commands as needed to manage data integrity. Analogous to a raid
      controller with RAM cache.
     </p></dd><dt id="cache.none"><span class="term ">none</span></dt><dd><p>
      This mode causes the hypervisor to interact with
      the disk image file or block device with
      <code class="literal">O_DIRECT</code> semantics. The host page cache is bypassed
      and I/O happens directly between the hypervisor user space buffers and the
      storage
      device. Because the actual storage device may report a write as
      completed when placed in its write queue only, the guest's virtual
      storage adapter is informed that there is a writeback cache. The
      guest would be expected to send down flush commands as needed to
      manage data integrity. Performance-wise, it is equivalent to direct
      access to your host's disk.
     </p></dd><dt id="cache.unsafe"><span class="term ">unsafe</span></dt><dd><p>
      This mode is similar to the <code class="literal">writeback</code> mode
      discussed above. The key aspect of this <span class="quote">“<span class="quote">unsafe</span>”</span> mode, is
      that all flush commands from the guests are ignored. Using this mode
      implies that the user has accepted the trade-off of performance over
      risk of data loss in case of a host failure. Useful, for example,
      during guest installation, but not for production workloads.
     </p></dd><dt id="cache.directsync"><span class="term ">directsync</span></dt><dd><p>
      This mode causes the hypervisor to interact with the disk image file or
      block device with both <code class="literal">O_DSYNC</code> and
      <code class="literal">O_DIRECT</code> semantics. This means, writes are reported as
      completed only when the data has been committed to the storage device,
      and when it is also desirable to bypass the host page cache. Like
      <a class="xref" href="cha.cachemodes.html#cache.writethrough">writethrough</a>, it is helpful to guests that do
      not send flushes when needed. It was the last cache mode added,
      completing the possible combinations of caching and direct access
      semantics.
     </p></dd></dl></div></div><div class="sect1 " id="qemu.cachemodes.data_integrity"><div class="titlepage"><div><div><h2 class="title" id="qemu.cachemodes.data_integrity"><span class="number">15.3 </span><span class="name">Data Integrity Implications of Cache Modes</span> <a title="Permalink" class="permalink" href="cha.cachemodes.html#qemu.cachemodes.data_integrity">#</a></h2></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="idm139769515599072"><span class="term ">writethrough, none, directsync</span></dt><dd><p>
      These are the safest modes, and considered equally safe, given that
      the guest operating system is <span class="quote">“<span class="quote">modern and well behaved</span>”</span>,
      which means that it uses flushes as needed. If you have a suspect
      guest, use <span class="emphasis"><em>writethough</em></span>, or
      <span class="emphasis"><em>directsync</em></span>. Note that some file systems are not
      compatible with <code class="literal">none</code> or
      <code class="literal">directsync</code>, as they do not support O_DIRECT,
      which these cache modes rely on.
     </p></dd><dt id="idm139769515594784"><span class="term ">writeback</span></dt><dd><p>
      This mode informs the guest of the presence of a write cache, and
      relies on the guest to send flush commands as needed to maintain data
      integrity within its disk image. This is a common storage design which
      is completely accounted for within modern file systems. This mode exposes
      the guest to data loss in the unlikely case of a host failure,
      because there is a window of time between the time a
      write is reported as completed, and that write being committed to the
      storage device.
     </p></dd><dt id="idm139769515592464"><span class="term ">unsafe</span></dt><dd><p>
      This mode is similar to <span class="emphasis"><em>writeback</em></span> caching except for
      the following: the guest flush
      commands are ignored, nullifying the data integrity control of these
      flush commands, and resulting in a higher risk of data loss because of
      host failure. The name <span class="quote">“<span class="quote">unsafe</span>”</span> should serve as a warning
      that there is a much higher potential for data loss because of a host
      failure than with the other modes. As the guest terminates,
      the cached data is flushed at that time.
     </p></dd></dl></div></div><div class="sect1 " id="qemu.cachemodes.performance"><div class="titlepage"><div><div><h2 class="title" id="qemu.cachemodes.performance"><span class="number">15.4 </span><span class="name">Performance Implications of Cache Modes</span> <a title="Permalink" class="permalink" href="cha.cachemodes.html#qemu.cachemodes.performance">#</a></h2></div></div></div><p>
   The choice to make full use of the page cache, or to write through it, or
   to bypass it altogether can have dramatic performance implications. Other
   factors that influence disk performance include the capabilities of the
   actual storage system, what disk image format is used, the potential size
   of the page cache and the IO scheduler used. Additionally, not flushing
   the write cache increases performance, but with risk, as noted above. As
   a general rule, high-end systems typically perform best with the cache mode
   <code class="literal">none</code>, because of the reduced data copying that
   occurs. The potential benefit of having multiple guests share the common
   host page cache, the ratio of reads to writes, and the use of AIO mode
   <code class="literal">native</code> (see below) should also be considered.
  </p></div><div class="sect1 " id="sec.cache.mode.live.migration"><div class="titlepage"><div><div><h2 class="title" id="sec.cache.mode.live.migration"><span class="number">15.5 </span><span class="name">Effect of Cache Modes on Live Migration</span> <a title="Permalink" class="permalink" href="cha.cachemodes.html#sec.cache.mode.live.migration">#</a></h2></div></div></div><p>
   The caching of storage data and metadata restricts the configurations
   that support live migration. Currently, only <code class="literal">raw</code>,
   <code class="literal">qcow2</code> and <code class="literal">qed</code> image formats can be
   used for live migration. If a clustered file system is used, all cache
   modes support live migration. Otherwise the only cache mode that supports
   live migration on read/write shared storage is <code class="literal">none</code>.
  </p><p>
   The <code class="systemitem">libvirt</code> management layer includes checks for
   migration compatibility based on several factors. If the guest
   storage is hosted on a clustered file system, is read-only or is marked
   shareable, then the cache mode is ignored when determining if migration
   can be allowed. Otherwise <code class="systemitem">libvirt</code> will not allow
   migration unless the cache mode is set to <code class="literal">none</code>.
   However, this restriction can be overridden with the
   <span class="quote">“<span class="quote">unsafe</span>”</span> option to the migration APIs, which is also
   supported by <code class="command">virsh</code>, as for example in
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>virsh migrate --live --unsafe</pre></div><div id="idm139769515577376" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.png" /><h6>Tip</h6><p>
    The cache mode <code class="literal">none</code> is required for the AIO mode setting
    <code class="literal">native</code>. If another cache mode is used, then the
    AIO mode will silently be switched back to the default <code class="literal">threads</code>. The
    guest flush within the host is implemented using
    <code class="systemitem">fdatasync()</code>.
   </p></div></div></div></div><div class="page-bottom"><div id="_bottom-navigation"><a class="nav-link" href="sec.kvm.managing.clock.html"><span class="next-icon">→</span><span class="nav-label"><span class="number">Chapter 16 </span>VM Guest Clock Settings</span></a><a class="nav-link" href="part.virt.common.html"><span class="prev-icon">←</span><span class="nav-label"><span class="number">Part III </span>Hypervisor-Independent Features</span></a></div><div id="_share-print"><div class="online-contents share"><strong>Share this page: </strong><span class="share-buttons"><span id="_share-fb" class="bottom-button">Facebook</span><span class="spacer"> • </span><span id="_share-gp" class="bottom-button">Google+</span><span class="spacer"> • </span><span id="_share-tw" class="bottom-button">Twitter</span><span class="spacer"> • </span><span id="_share-mail" class="bottom-button">E-Mail</span></span></div><div class="print"><span id="_print-button" class="bottom-button">Print this page</span></div><div class="clearme"></div></div></div></div><div id="_inward"></div></div><div id="_footer-wrap"><div id="_footer"><p>©
        2018 
        SUSE</p><ul><li><a href="http://www.suse.com/company/careers/" target="_top">Careers</a></li><li><a href="http://www.suse.com/company/legal/" target="_top">Legal</a></li><li><a href="http://www.suse.com/company/" target="_top">About</a></li><li><a href="http://www.suse.com/ContactsOffices/contacts_offices.jsp" target="_top">Contact Us</a></li></ul></div></div></body></html>